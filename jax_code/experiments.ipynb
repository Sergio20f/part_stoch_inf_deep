{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/sergioco/anaconda3/envs/jaxsde/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import arch, brax\n",
    "from datasets import get_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from jax.example_libraries import optimizers, stax\n",
    "from jax.tree_util import tree_map\n",
    "from utils import get_calibration, jaxRNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10C(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, severity_level=3):\n",
    "        # Validate severity level\n",
    "        if severity_level not in range(1, 6):\n",
    "            raise ValueError(\"Severity level must be between 1 and 5.\")\n",
    "            \n",
    "        self.data_files = sorted([f for f in Path(data_dir).glob('*.npy') if 'labels.npy' not in str(f)])\n",
    "        self.labels = np.load(Path(data_dir) / 'labels.npy')\n",
    "        self.transform = transform\n",
    "        self.severity_level = severity_level\n",
    "        # Each severity level has 10000 images\n",
    "        self.images_per_level = 10000\n",
    "        self.start_idx = self.images_per_level * (severity_level - 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming same number of images per severity level\n",
    "        return self.images_per_level\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Adjust idx based on severity level\n",
    "        adjusted_idx = self.start_idx + idx\n",
    "        # Assuming data_files are in the correct order\n",
    "        data = np.load(self.data_files[adjusted_idx // self.images_per_level])[adjusted_idx % self.images_per_level]\n",
    "        label = self.labels[adjusted_idx % self.images_per_level]\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading checkpoints...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: sdebnn\n",
      "Using CIFAR-10-C dataset at severity level 2\n",
      "Number of test batches: 1\n",
      "Successfully loaded checkpoints for epoch 95 with best validation accuracy 0.7594000101089478\n"
     ]
    }
   ],
   "source": [
    "# Define all the args\n",
    "model= 'sdebnn' #'psdebnn'\n",
    "print(\"Using model:\", model)\n",
    "output='output-sdebnn'\n",
    "seed=0\n",
    "stl=False\n",
    "lr=0.0007\n",
    "epochs=100\n",
    "bs=128\n",
    "test_bs=100\n",
    "nsamples=1\n",
    "w_init=-1.0\n",
    "b_init=-1.0\n",
    "p_init=-1.0\n",
    "pause_every=200\n",
    "no_drift=False\n",
    "ou_dw=True\n",
    "kl_coef=0.001\n",
    "diff_coef=0.1\n",
    "ood=True\n",
    "ds='cifar10c'\n",
    "severity_level = 2 # CHANGE ACCORDINGLY\n",
    "no_xt=True\n",
    "acc_grad=1\n",
    "aug=0\n",
    "remat=False\n",
    "ema=0.999\n",
    "meanfield_sdebnn=False\n",
    "infer_w0=False\n",
    "w0_prior_std=0.1\n",
    "disable_test=False\n",
    "verbose=True\n",
    "nblocks='2-2-2'\n",
    "block_type=0\n",
    "fx_dim=64\n",
    "fx_actfn='softplus'\n",
    "fw_dims='2-128-2'\n",
    "fw_actfn='softplus'\n",
    "lr_sched='constant'\n",
    "rng_generator = jaxRNG(seed= seed)\n",
    "\n",
    "ode_first=True\n",
    "timecut=0.1\n",
    "method_ode='euler'\n",
    "\n",
    "if ds == 'cifar10':\n",
    "    print(\"Using CIFAR-10 dataset\")\n",
    "    train_loader, train_eval_loader, val_loader, test_loader, input_size, train_size = get_dataset(bs, test_bs, \"cifar10\")\n",
    "\n",
    "    indices = torch.randperm(len(test_loader.dataset)).tolist() # Check\n",
    "    test_subset_indices = indices[:test_bs]\n",
    "    test_subset = torch.utils.data.Subset(test_loader.dataset, test_subset_indices) # Check\n",
    "    test_loader = DataLoader(test_subset, batch_size=test_bs, shuffle=False)\n",
    "    num_batches = len(test_loader)\n",
    "    print(f\"Number of test batches: {num_batches}\")\n",
    "\n",
    "elif ds == 'cifar10c':\n",
    "    print(\"Using CIFAR-10-C dataset at severity level\", severity_level)\n",
    "    # Need to download manually from https://zenodo.org/records/2535967/files/CIFAR-10-C.tar?download=1\n",
    "    data_dir = \"data/cifar10c\"\n",
    "\n",
    "    # Define your transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    cifar10c_dataset = CIFAR10C(data_dir=data_dir, transform=transform, severity_level=1)\n",
    "\n",
    "    # Create test DataLoader for the CIFAR-10-C dataset\n",
    "    #test_loader = DataLoader(cifar10c_dataset, batch_size=test_bs, shuffle=True)\n",
    "    #num_batches = len(test_loader)\n",
    "    #print(f\"Number of test batches: {num_batches}\")\n",
    "\n",
    "    # Since DataLoader will iterate over the dataset, we can just grab the first 1000 images\n",
    "    # during the actual testing loop. If we want to explicitly create a smaller dataset:\n",
    "\n",
    "    indices = torch.randperm(len(cifar10c_dataset)).tolist()\n",
    "    # Get the first 1000 indices after shuffling\n",
    "    test_subset_indices = indices[:test_bs]\n",
    "    test_subset = torch.utils.data.Subset(cifar10c_dataset, test_subset_indices)\n",
    "    test_loader = DataLoader(test_subset, batch_size=test_bs, shuffle=False)\n",
    "    num_batches = len(test_loader)\n",
    "    print(f\"Number of test batches: {num_batches}\")\n",
    "else:\n",
    "    raise ValueError(\"Dataset not supported!\")\n",
    "    \n",
    "# SDEBNN specific\n",
    "mf = partial(brax.MeanField, disable=True) if kl_coef == 0. else brax.MeanField\n",
    "fw_dims = list(map(int, fw_dims.split(\"-\")))\n",
    "layers = [mf(arch.Augment( aug))]\n",
    "nblocks = list(map(int, nblocks.split(\"-\")))\n",
    "opt_init, opt_update, get_params = optimizers.adam(7e-4)\n",
    "\n",
    "# Load the checkpoint if it exists\n",
    "checkpoint_path = os.path.join(output, 'best_model_checkpoint.pkl')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    logging.warning(\"Loading checkpoints...\")\n",
    "    with open(checkpoint_path, \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "\n",
    "    # Extract states from the checkpoint\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    global_step = checkpoint['global_step']\n",
    "    opt_state = checkpoint['optimizer_state']\n",
    "    ema_params = checkpoint['ema_state']\n",
    "    params = checkpoint['model_state']  # Loaded parameters\n",
    "    print(f\"Successfully loaded checkpoints for epoch {start_epoch} with best validation accuracy {best_val_acc}\")\n",
    "else:\n",
    "    raise SystemExit(\"No checkpoint found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment\n",
      "there were [ 0.  0.  2.  2.  8. 11. 11. 10. 12. 44.] items in bins 1-10\n",
      "Inference time with 30 steps: 11.223167181015015 (s)\n",
      "Accuracy with 30 steps: 0.8100000023841858\n",
      "NLL with 30 steps: 0.0057860747911036015\n",
      "ECE with 30 steps: 0.06679116514663966\n",
      "Experiment run sucessfully!\n"
     ]
    }
   ],
   "source": [
    "def _nll(params, batch, rng):\n",
    "    inputs, targets = batch\n",
    "    preds, kl, info_dict = _predict(params, inputs, rng=rng, full_output=False)\n",
    "    nll = -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "    return preds, nll, kl, info_dict\n",
    "\n",
    "\n",
    "@partial(jit, static_argnums=(3,))\n",
    "def sep_loss(params, batch, rng, kl_coef):  # no backprop\n",
    "    preds, nll, kl, _ = _nll(params, batch, rng)\n",
    "    if kl_coef > 0:\n",
    "        obj_loss = nll + kl * kl_coef\n",
    "    else:\n",
    "        obj_loss = nll\n",
    "    _sep_loss = {'loss': obj_loss, 'kl': kl, 'nll': nll, 'preds': preds}\n",
    "    return obj_loss, _sep_loss\n",
    "\n",
    "@partial(jit, static_argnums=(3,))\n",
    "def loss(params, batch, rng, kl_coef):  # backprop so checkpoint\n",
    "    _, nll, kl, _ = jax.checkpoint(_nll)(params, batch, rng)\n",
    "    if kl_coef > 0:\n",
    "        return nll + kl * kl_coef\n",
    "    else:\n",
    "        return nll\n",
    "\n",
    "@jit\n",
    "def predict(params, inputs, rng): \n",
    "    return _predict(params, inputs, rng=rng, full_output=True)\n",
    "\n",
    "@partial(jit, static_argnums=(2,))\n",
    "def accuracy(params, data, nsamples, rng):\n",
    "    inputs, targets = data\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    rngs = jax.random.split(rng, nsamples)\n",
    "    preds, _, info_dic = vmap(predict, in_axes=(None, None, 0))(params, inputs, rngs)\n",
    "    preds = jnp.stack(preds, axis=0)\n",
    "    avg_preds = preds.mean(0)\n",
    "    predicted_class = jnp.argmax(avg_preds, axis=1)\n",
    "    n_correct = jnp.sum(predicted_class == target_class)\n",
    "    n_total = inputs.shape[0]\n",
    "    wts = info_dic[model+'_w'] \n",
    "    wts = jnp.stack(wts, axis=0)\n",
    "    avg_wts = wts.mean(0)\n",
    "    return n_correct, n_total, avg_preds, avg_wts\n",
    "\n",
    "def update_ema(ema_params, params, momentum=0.999):\n",
    "    return tree_map(lambda e, p: e * momentum + p * (1 - momentum), ema_params, params)\n",
    "\n",
    "def evaluate(params, data_loader, input_size, nsamples, rng_generator, kl_coef):\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "    nll = 0\n",
    "    kl = 0\n",
    "    logits = np.array([])\n",
    "    wts = np.array([])\n",
    "    labels = np.array([])\n",
    "    for inputs, targets in data_loader:\n",
    "        targets = jax.nn.one_hot(jnp.array(targets), num_classes=10)\n",
    "        inputs = jnp.array(inputs).reshape((-1,) + (input_size[-1],) + input_size[:2])\n",
    "        inputs = jnp.transpose(inputs, (0, 2, 3, 1))  # Permute from NCHW to NHWC\n",
    "        batch_correct, batch_total, _logits, _wts = accuracy(\n",
    "            params, (inputs, targets), nsamples, rng_generator.next()\n",
    "        )\n",
    "        n_correct = n_correct + batch_correct\n",
    "        _, batch_nll, batch_kl, _ = jit(_nll)(params, (inputs, targets), rng_generator.next())\n",
    "        if n_total == 0:\n",
    "            logits = np.array(_logits)\n",
    "            wts = np.array(_wts)\n",
    "            labels = np.array(targets)\n",
    "        else:\n",
    "            logits = np.concatenate([logits, np.array(_logits)], axis=0)\n",
    "            wts = np.concatenate([wts, np.array(_wts)], axis=0)\n",
    "            labels = np.concatenate([labels, targets], axis=0)\n",
    "        n_total = n_total + batch_total\n",
    "        nll = nll + batch_nll\n",
    "        kl = kl + batch_kl\n",
    "    return n_correct / n_total, jnp.stack(logits, axis=0), labels, nll / n_total, kl / n_total, jnp.stack(wts, axis=0)\n",
    "\n",
    "nsteps = 30 # CHANGE FOR EACH EXPERIMENT\n",
    "\n",
    "if ood:\n",
    "    print(\"Starting OOD experiment\")\n",
    "else:\n",
    "    print(\"Starting ID experiment\")\n",
    "\n",
    "if model == \"sdebnn\":\n",
    "    for i, nb in enumerate(nblocks):\n",
    "        fw = arch.MLP(fw_dims, actfn=fw_actfn, xt=no_xt, ou_dw=ou_dw, nonzero_w=w_init, nonzero_b=b_init, p_scale=p_init)  # weight network is time dependent\n",
    "        if meanfield_sdebnn:\n",
    "            layers.extend([mf(brax.SDEBNN(block_type,\n",
    "                                            fx_dim,\n",
    "                                            fx_actfn,\n",
    "                                            fw,\n",
    "                                            diff_coef=diff_coef,\n",
    "                                            stl=stl,\n",
    "                                            xt=no_xt,\n",
    "                                            nsteps=nsteps,\n",
    "                                            remat=remat,\n",
    "                                            w_drift=not no_drift,\n",
    "                                            stax_api=True,\n",
    "                                            infer_initial_state=infer_w0,\n",
    "                                            initial_state_prior_std=w0_prior_std)) for _ in range(nb)\n",
    "            ])\n",
    "        else:\n",
    "            layers.extend([brax.SDEBNN( block_type,\n",
    "                                        fx_dim,\n",
    "                                        fx_actfn,\n",
    "                                        fw,\n",
    "                                        diff_coef=diff_coef,\n",
    "                                        stl=stl,\n",
    "                                        xt=no_xt,\n",
    "                                        nsteps=nsteps,\n",
    "                                        remat=remat,\n",
    "                                        w_drift=not no_drift,\n",
    "                                        infer_initial_state=infer_w0,\n",
    "                                        initial_state_prior_std=w0_prior_std) for _ in range(nb)\n",
    "            ])\n",
    "        if i < len(nblocks) - 1:\n",
    "            layers.append(mf(arch.SqueezeDownsample(2)))\n",
    "    layers.append(mf(stax.serial(stax.Flatten, stax.Dense(10), stax.LogSoftmax)))\n",
    "\n",
    "    init_random_params, _predict = brax.bnn_serial(*layers)\n",
    "\n",
    "elif model == \"psdebnn\":\n",
    "    for i, nb in enumerate(nblocks):\n",
    "        fw = arch.MLP(fw_dims, actfn=fw_actfn, xt=no_xt, ou_dw=ou_dw, nonzero_w=w_init, nonzero_b=b_init, p_scale=p_init)  # weight network is time dependent\n",
    "        if meanfield_sdebnn:\n",
    "            layers.extend([mf(brax.PSDEBNN( block_type,\n",
    "                                            fx_dim,\n",
    "                                            fx_actfn,\n",
    "                                            fw,\n",
    "                                            diff_coef=diff_coef,\n",
    "                                            stl=stl,\n",
    "                                            xt=no_xt,\n",
    "                                            nsteps=nsteps,\n",
    "                                            remat=remat,\n",
    "                                            w_drift=not no_drift,\n",
    "                                            stax_api=True,\n",
    "                                            infer_initial_state=infer_w0,\n",
    "                                            initial_state_prior_std=w0_prior_std,\n",
    "                                            ode_first=ode_first,\n",
    "                                            timecut=timecut,\n",
    "                                            method_ode=method_ode)) for _ in range(nb)\n",
    "            ])\n",
    "        else:\n",
    "            layers.extend([brax.PSDEBNN(block_type,\n",
    "                                        fx_dim,\n",
    "                                        fx_actfn,\n",
    "                                        fw,\n",
    "                                        diff_coef=diff_coef,\n",
    "                                        stl=stl,\n",
    "                                        xt=no_xt,\n",
    "                                        nsteps=nsteps,\n",
    "                                        remat=remat,\n",
    "                                        w_drift=not no_drift,\n",
    "                                        infer_initial_state=infer_w0,\n",
    "                                        initial_state_prior_std=w0_prior_std,\n",
    "                                        ode_first=ode_first,\n",
    "                                        timecut=timecut,\n",
    "                                        method_ode=method_ode) for _ in range(nb)\n",
    "            ])\n",
    "        if i < len(nblocks) - 1:\n",
    "            layers.append(mf(arch.SqueezeDownsample(2)))\n",
    "    layers.append(mf(stax.serial(stax.Flatten, stax.Dense(10), stax.LogSoftmax)))\n",
    "\n",
    "    init_random_params, _predict = brax.bnn_serial(*layers)\n",
    "\n",
    "# for inputs, targets in tqdm(test_loader): # evaluate already deals with the loop\n",
    "start_time = time.time()\n",
    "acc, logits, targets, nll, _, _ = evaluate(params, test_loader, input_size, nsamples, rng_generator, kl_coef=kl_coef)\n",
    "\n",
    "# Calculate inference time\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Convert logits to probabilities\n",
    "if ood:\n",
    "    probabilities_ood = jax.nn.softmax(logits)\n",
    "    # TODO: might be better to use utils.ECE or utils.compute_acc_bin\n",
    "    cal = get_calibration(targets, probabilities_ood)\n",
    "else:\n",
    "    probabilities_id = jax.nn.softmax(logits) # probabilities_ood when ood data is used\n",
    "    # TODO: might be better to use utils.ECE or utils.compute_acc_bin\n",
    "    cal = get_calibration(targets, probabilities_id)\n",
    "\n",
    "print(f\"Inference time with {nsteps} steps: {inference_time} (s)\")\n",
    "print(f\"Accuracy with {nsteps} steps: {acc}\")\n",
    "print(f\"NLL with {nsteps} steps: {nll}\")\n",
    "print(f\"ECE with {nsteps} steps: {cal['ece']}\")\n",
    "\n",
    "print(\"Experiment run sucessfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOD Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using maximum softmax probabilities as confidence scores\n",
    "probabilities_id_np = np.array(probabilities_id)\n",
    "probabilities_id_torch = torch.tensor(probabilities_id_np)\n",
    "id_probs, _ = torch.max(probabilities_id_torch, dim=1)\n",
    "\n",
    "probabilities_ood_np = np.array(probabilities_ood)\n",
    "probabilities_ood_torch = torch.tensor(probabilities_ood_np)\n",
    "ood_probs, _ = torch.max(probabilities_ood_torch, dim=1)\n",
    "\n",
    "# Assume `id_probs` and `ood_probs` are the maximum softmax probabilities for ID and OOD data respectively\n",
    "scores = np.concatenate([id_probs, ood_probs])\n",
    "labels = np.concatenate([np.zeros_like(id_probs), np.ones_like(ood_probs)])  # 0 for ID, 1 for OOD\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "auc = roc_auc_score(labels, scores)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for OOD Detection')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Entropy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of high uncertainty predictions: 3\n",
      "Number of low uncertainty predictions: 97\n",
      "Mean entropy: 0.5965458154678345 and std entropy: 0.5066224336624146\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Compare with Ground Truth: If possible, compare entropy values with the ground truth to see if higher entropy correlates with incorrect predictions.\n",
    "- Correlation Analysis: Look for correlations between entropy and other factors, e.g. difficulty of examples, to understand in what situations the models are more uncertain.\n",
    "\n",
    "WHAT WE EXPECT:\n",
    "1. Well-calibrated Model: A model with good uncertainty calibration will have a wide range of entropy values, with higher entropy corresponding to less certain predictions.\n",
    "2. Overconfident Model: If a model is overconfident, you'll see a distribution skewed towards lower entropy values, even for incorrect predictions.\n",
    "3. Underconfident Model: Conversely, an underconfident model will have a distribution skewed towards higher entropy values, indicating uncertainty even in correct predictions.\n",
    "4. Partially vs. Fully Stochastic: The partially stochastic model might show a tighter distribution if it's better at distinguishing clear cases, while the fully stochastic model might exhibit higher entropy overall, reflecting greater inherent uncertainty.\n",
    "\n",
    "The key is to see if higher entropy aligns with instances where the model should be uncertain (e.g., incorrect predictions, OOD data) and lower entropy aligns with correct and confident predictions.\n",
    "\"\"\"\n",
    "probabilities_np = np.array(probabilities)\n",
    "probabilities_torch = torch.tensor(probabilities_np)\n",
    "\n",
    "entropy = -torch.sum(probabilities_torch * torch.log(probabilities_torch), dim=1)\n",
    "mean_entropy = torch.mean(entropy) # Should be high for OOD data\n",
    "std_entropy = torch.std(entropy)\n",
    "\n",
    "uncertainty_threshold = 1.\n",
    "# Classify predictions\n",
    "high_uncertainty_predictions = entropy.numpy() > uncertainty_threshold\n",
    "low_uncertainty_predictions = entropy.numpy() <= uncertainty_threshold\n",
    "print(f\"Number of high uncertainty predictions: {np.sum(high_uncertainty_predictions)}\")\n",
    "print(f\"Number of low uncertainty predictions: {np.sum(low_uncertainty_predictions)}\")\n",
    "\n",
    "print(f\"Mean entropy: {mean_entropy} and std entropy: {std_entropy}\")\n",
    "plt.hist(entropy.numpy(), bins=20)\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Uncertainty')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxsde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
