{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import jax\n",
    "from jax.example_libraries import stax\n",
    "from jax import grad, jit, vmap\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datasets import get_dataset\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "from utils import get_calibration, jaxRNG\n",
    "from sdebnn_classification import evaluate\n",
    "import brax\n",
    "import arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nll(params, batch, rng):\n",
    "    inputs, targets = batch\n",
    "    preds, kl, info_dict = _predict(params, inputs, rng=rng, full_output=False)\n",
    "    nll = -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "    return preds, nll, kl, info_dict\n",
    "\n",
    "def predict(params, inputs, rng): \n",
    "    return _predict(params, inputs, rng=rng, full_output=True)\n",
    "\n",
    "@partial(jit, static_argnums=(2,))\n",
    "def accuracy(params, data, nsamples, rng):\n",
    "    inputs, targets = data\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    rngs = jax.random.split(rng, nsamples)\n",
    "    preds, _, info_dic = vmap(predict, in_axes=(None, None, 0))(params, inputs, rngs)\n",
    "    preds = jnp.stack(preds, axis=0)\n",
    "    avg_preds = preds.mean(0)\n",
    "    predicted_class = jnp.argmax(avg_preds, axis=1)\n",
    "    n_correct = jnp.sum(predicted_class == target_class)\n",
    "    n_total = inputs.shape[0]\n",
    "    wts = info_dic['sdebnn_w']\n",
    "    wts = jnp.stack(wts, axis=0)\n",
    "    avg_wts = wts.mean(0)\n",
    "    return n_correct, n_total, avg_preds, avg_wts\n",
    "\n",
    "def evaluate(params, data_loader, input_size, nsamples, rng_generator):\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "    nll = 0\n",
    "    kl = 0\n",
    "    logits = np.array([])\n",
    "    wts = np.array([])\n",
    "    labels = np.array([])\n",
    "    for inputs, targets in data_loader:\n",
    "        targets = jax.nn.one_hot(jnp.array(targets), num_classes=10)\n",
    "        inputs = jnp.array(inputs).reshape((-1,) + (input_size[-1],) + input_size[:2])\n",
    "        inputs = jnp.transpose(inputs, (0, 2, 3, 1))  # Permute from NCHW to NHWC\n",
    "        batch_correct, batch_total, _logits, _wts = accuracy(\n",
    "            params, (inputs, targets), nsamples, rng_generator.next(),\n",
    "        ) # _logits (nbatch, nclass)\n",
    "        n_correct = n_correct + batch_correct\n",
    "        _, batch_nll, batch_kl, _ = jit(_nll)(params, (inputs, targets), rng_generator.next())\n",
    "        if n_total == 0:\n",
    "            logits = np.array(_logits)\n",
    "            wts = np.array(_wts)\n",
    "            labels = np.array(targets)\n",
    "        else:\n",
    "            logits = np.concatenate([logits, np.array(_logits)], axis=0)\n",
    "            wts = np.concatenate([wts, np.array(_wts)], axis=0)\n",
    "            labels = np.concatenate([labels, targets], axis=0)\n",
    "        n_total = n_total + batch_total\n",
    "        nll = nll + batch_nll\n",
    "        kl = kl + batch_kl\n",
    "    return n_correct / n_total, jnp.stack(logits, axis=0), labels, nll / n_total, kl / n_total, jnp.stack(wts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Inputs shape in evaluate (1000, 32, 32, 3)\n",
      "Inputs shape in accuracy (1000, 32, 32, 3)\n",
      "rngs shape in accuracy (1000, 2)\n",
      "Entering predict function\n",
      "Inputs shape in predict: (32, 32, 3)\n",
      "RNG state in predict: Traced<ShapedArray(uint32[2])>with<DynamicJaxprTrace(level=1/0)>\n",
      "data type of inputs: <class 'jax._src.interpreters.partial_eval.DynamicJaxprTracer'>\n",
      "Error encountered in _predict: tuple index out of range\n",
      "Inputs: Traced<ShapedArray(float32[32,32,3])>with<DynamicJaxprTrace(level=1/0)>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# for inputs, targets in tqdm(test_loader): # evaluate already deasl with the loop\u001b[39;00m\n\u001b[1;32m    138\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 139\u001b[0m _, logits, targets, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Calculate inference time\u001b[39;00m\n\u001b[1;32m    142\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[17], line 72\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(params, data_loader, input_size, nsamples, rng_generator)\u001b[0m\n\u001b[1;32m     69\u001b[0m inputs \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mtranspose(inputs, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Permute from NCHW to NHWC\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs shape in evaluate\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# Should be ((1000, 32, 32, 3),)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m batch_correct, batch_total, _logits, _wts \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# _logits (nbatch, nclass)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m n_correct \u001b[38;5;241m=\u001b[39m n_correct \u001b[38;5;241m+\u001b[39m batch_correct\n\u001b[1;32m     76\u001b[0m _, batch_nll, batch_kl, _ \u001b[38;5;241m=\u001b[39m jit(_nll)(params, (inputs, targets), rng_generator\u001b[38;5;241m.\u001b[39mnext())\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(params, data, nsamples, rng)\u001b[0m\n\u001b[1;32m     37\u001b[0m single_rng_state \u001b[38;5;241m=\u001b[39m rngs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Call the predict function directly\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m single_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_rng_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Print the output to check if it works correctly\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingle Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m, single_pred)\n",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(params, inputs, rng)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Optional: print more details about params and inputs\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#print(\"Params:\", params)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(params, inputs, rng)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming _predict is a function called within predict\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError encountered in _predict:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/test_code/part_stoch_inf_deep/jax_code/brax.py:209\u001b[0m, in \u001b[0;36mbnn_serial.<locals>.apply_fun\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m infodict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fun, param, rng \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(apply_funs, params, rngs):\n\u001b[0;32m--> 209\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    211\u001b[0m         inputs, layer_kl \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxsde/lib/python3.11/site-packages/jax/example_libraries/stax.py:355\u001b[0m, in \u001b[0;36mshape_dependent.<locals>.apply_fun\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fun\u001b[39m(params, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 355\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m](params, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/test_code/part_stoch_inf_deep/jax_code/brax.py:40\u001b[0m, in \u001b[0;36mSDEBNN.<locals>.make_layer\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Creates the unflatten_w function.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# temp; not used.\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m x_shape, tmp_w \u001b[38;5;241m=\u001b[39m \u001b[43mfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m input_shape \u001b[38;5;241m==\u001b[39m x_shape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfx needs to have the same input and output shapes but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m flat_w, unflatten_w \u001b[38;5;241m=\u001b[39m ravel_pytree(tmp_w)\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxsde/lib/python3.11/site-packages/jax/example_libraries/stax.py:300\u001b[0m, in \u001b[0;36mserial.<locals>.init_fun\u001b[0;34m(rng, input_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m init_fun \u001b[38;5;129;01min\u001b[39;00m init_funs:\n\u001b[1;32m    299\u001b[0m   rng, layer_rng \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[0;32m--> 300\u001b[0m   input_shape, param \u001b[38;5;241m=\u001b[39m \u001b[43minit_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m   params\u001b[38;5;241m.\u001b[39mappend(param)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_shape, params\n",
      "File \u001b[0;32m~/test_code/part_stoch_inf_deep/jax_code/diffeq_layers.py:141\u001b[0m, in \u001b[0;36mConcatConv2D.<locals>.init_fun\u001b[0;34m(rng, input_shape)\u001b[0m\n\u001b[1;32m    139\u001b[0m concat_input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m    \u001b[38;5;66;03m# add time channel dim\u001b[39;00m\n\u001b[1;32m    140\u001b[0m concat_input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(concat_input_shape)\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_fun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_input_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxsde/lib/python3.11/site-packages/jax/example_libraries/stax.py:75\u001b[0m, in \u001b[0;36mGeneralConv.<locals>.init_fun\u001b[0;34m(rng, input_shape)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fun\u001b[39m(rng, input_shape):\n\u001b[1;32m     74\u001b[0m   filter_shape_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(filter_shape)\n\u001b[0;32m---> 75\u001b[0m   kernel_shape \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mout_chan\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlhs_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilter_shape_iter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrhs_spec\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mconv_general_shape_tuple(\n\u001b[1;32m     79\u001b[0m       input_shape, kernel_shape, strides, padding, dimension_numbers)\n\u001b[1;32m     80\u001b[0m   bias_shape \u001b[38;5;241m=\u001b[39m [out_chan \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m out_spec]\n",
      "File \u001b[0;32m~/anaconda3/envs/jaxsde/lib/python3.11/site-packages/jax/example_libraries/stax.py:76\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fun\u001b[39m(rng, input_shape):\n\u001b[1;32m     74\u001b[0m   filter_shape_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(filter_shape)\n\u001b[1;32m     75\u001b[0m   kernel_shape \u001b[38;5;241m=\u001b[39m [out_chan \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m                   \u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlhs_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m     77\u001b[0m                   \u001b[38;5;28mnext\u001b[39m(filter_shape_iter) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m rhs_spec]\n\u001b[1;32m     78\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mconv_general_shape_tuple(\n\u001b[1;32m     79\u001b[0m       input_shape, kernel_shape, strides, padding, dimension_numbers)\n\u001b[1;32m     80\u001b[0m   bias_shape \u001b[38;5;241m=\u001b[39m [out_chan \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m out_spec]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def _nll(params, batch, rng):\n",
    "    inputs, targets = batch\n",
    "    print(\"Inputs shape in nll\", inputs.shape)\n",
    "    preds, kl, info_dict = _predict(params, inputs, rng=rng, full_output=False)\n",
    "    nll = -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "    return preds, nll, kl, info_dict\n",
    "\n",
    "def predict(params, inputs, rng):\n",
    "    print(\"Entering predict function\")\n",
    "    print(\"Inputs shape in predict:\", inputs.shape)\n",
    "    print(\"RNG state in predict:\", rng)\n",
    "    print(\"data type of inputs:\", type(inputs))\n",
    "\n",
    "    # Assuming _predict is a function called within predict\n",
    "    try:\n",
    "        result = _predict(params, inputs, rng=rng, full_output=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered in _predict:\", e)\n",
    "        print(\"Inputs:\", inputs)\n",
    "        raise e\n",
    "\n",
    "    return result\n",
    "\n",
    "@partial(jit, static_argnums=(2,))\n",
    "def accuracy(params, data, nsamples, rng):\n",
    "    inputs, targets = data\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    rngs = jax.random.split(rng, nsamples)\n",
    "\n",
    "    print('Inputs shape in accuracy', inputs.shape)\n",
    "    print('rngs shape in accuracy', rngs.shape)\n",
    "\n",
    "    # Select a single input and a single RNG state\n",
    "    single_input = inputs[0]\n",
    "    single_rng_state = rngs[0]\n",
    "\n",
    "    # Call the predict function directly\n",
    "    single_pred = predict(params, single_input, single_rng_state)\n",
    "\n",
    "    # Print the output to check if it works correctly\n",
    "    print('Single Prediction', single_pred)\n",
    "\n",
    "    # Directly pass inputs as an array to vmap\n",
    "    preds, _, info_dic = vmap(predict, in_axes=(None, 0, 0))(params, inputs, rngs)\n",
    "    print(\"Shape after vmap in accuracy:\", preds.shape)\n",
    "    preds = jnp.stack(preds, axis=0)\n",
    "    avg_preds = preds.mean(0)\n",
    "    predicted_class = jnp.argmax(avg_preds, axis=1)\n",
    "    n_correct = jnp.sum(predicted_class == target_class)\n",
    "    n_total = inputs.shape[0]\n",
    "    wts = info_dic['sdebnn_w']\n",
    "    wts = jnp.stack(wts, axis=0)\n",
    "    avg_wts = wts.mean(0)\n",
    "    return n_correct, n_total, avg_preds, avg_wts\n",
    "\n",
    "def evaluate(params, data_loader, input_size, nsamples, rng_generator):\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "    nll = 0\n",
    "    kl = 0\n",
    "    logits = np.array([])\n",
    "    wts = np.array([])\n",
    "    labels = np.array([])\n",
    "    for inputs, targets in data_loader:\n",
    "        targets = jax.nn.one_hot(jnp.array(targets), num_classes=10)\n",
    "        inputs = jnp.array(inputs).reshape((-1,) + (input_size[-1],) + input_size[:2])\n",
    "        inputs = jnp.transpose(inputs, (0, 2, 3, 1))  # Permute from NCHW to NHWC\n",
    "        \n",
    "        print(\"Inputs shape in evaluate\", inputs.shape) # Should be ((1000, 32, 32, 3),)\n",
    "        batch_correct, batch_total, _logits, _wts = accuracy(\n",
    "            params, (inputs, targets), nsamples, rng_generator.next(),\n",
    "        ) # _logits (nbatch, nclass)\n",
    "        n_correct = n_correct + batch_correct\n",
    "        _, batch_nll, batch_kl, _ = jit(_nll)(params, (inputs, targets), rng_generator.next())\n",
    "        if n_total == 0:\n",
    "            logits = np.array(_logits)\n",
    "            wts = np.array(_wts)\n",
    "            labels = np.array(targets)\n",
    "        else:\n",
    "            logits = np.concatenate([logits, np.array(_logits)], axis=0)\n",
    "            wts = np.concatenate([wts, np.array(_wts)], axis=0)\n",
    "            labels = np.concatenate([labels, targets], axis=0)\n",
    "        n_total = n_total + batch_total\n",
    "        nll = nll + batch_nll\n",
    "        kl = kl + batch_kl\n",
    "    return n_correct / n_total, jnp.stack(logits, axis=0), labels, nll / n_total, kl / n_total, jnp.stack(wts, axis=0)\n",
    "\n",
    "# Build model\n",
    "dt_list = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "fw_dims = list(map(int, \"2-128-2\".split(\"-\")))\n",
    "aug = 0\n",
    "nsamples = 1000\n",
    "rng_generator = jaxRNG(0)\n",
    "kl_coef = 1e-3\n",
    "\n",
    "mf = partial(brax.MeanField, disable=True) if kl_coef == 0. else brax.MeanField\n",
    "layers = [mf(arch.Augment(aug))]\n",
    "nblocks = list(map(int, \"2-2-2\".split(\"-\")))\n",
    "_, _, _, test_loader, input_size, _ = get_dataset(128, 1000, \"cifar10\")\n",
    "\n",
    "inference_times = []\n",
    "eces = []\n",
    "\n",
    "for dt in dt_list:\n",
    "    inference_times_dt = []\n",
    "    eces_dt = []\n",
    "    for i, nb in enumerate(nblocks):\n",
    "        fw = arch.MLP(fw_dims, actfn=\"softplus\", xt=False, ou_dw=False, nonzero_w=-1., nonzero_b=-1., p_scale=-1.)  # weight network is time dependent\n",
    "        layers.extend([brax.SDEBNN(fx_block_type=0,\n",
    "                                    fx_dim=64, # Shouldn't this be 128?\n",
    "                                    fx_actfn=\"softplus\",\n",
    "                                    fw=fw,\n",
    "                                    diff_coef=1e-4,\n",
    "                                    stl=False,\n",
    "                                    xt=False,\n",
    "                                    nsteps=20,\n",
    "                                    dt=dt,\n",
    "                                    remat=False,\n",
    "                                    w_drift=True,\n",
    "                                    infer_initial_state=False,\n",
    "                                    initial_state_prior_std=0.1) for _ in range(nb)\n",
    "            ])\n",
    "        if i < len(nblocks) - 1:\n",
    "            layers.append(mf(arch.SqueezeDownsample(2)))\n",
    "    layers.append(mf(stax.serial(stax.Flatten, stax.Dense(10), stax.LogSoftmax)))\n",
    "\n",
    "    _, _predict = brax.bnn_serial(*layers)\n",
    "\n",
    "    checkpoint_path = 'output/best_model_checkpoint.pkl'\n",
    "    with open(checkpoint_path, 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "\n",
    "    params = checkpoint['model_state']\n",
    "\n",
    "    # for inputs, targets in tqdm(test_loader): # evaluate already deasl with the loop\n",
    "    start_time = time.time()\n",
    "    _, logits, targets, _, _, _ = evaluate(params, test_loader, input_size, nsamples, rng_generator)\n",
    "\n",
    "    # Calculate inference time\n",
    "    inference_time = time.time() - start_time\n",
    "    inference_times.append(inference_time)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = jax.nn.softmax(logits)\n",
    "        \n",
    "    # Calculate ECE\n",
    "    cal = get_calibration(targets, probabilities)\n",
    "    eces.append(cal['ece'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxsde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
